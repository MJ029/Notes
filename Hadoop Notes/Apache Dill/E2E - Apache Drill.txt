************************************************E2E - Apache Drill****************************************
- Drill is an Apache open-source SQL query engine for Big Data exploration, in words Drill is the only columnar query engine that supports complex data.
- Apache Drill is a low latency distributed query engine for large-scale datasets, including structured and semi-structured/nested data.
- Drill is capable of querying nested data in formats like JSON and Parquet and performing dynamic schema discovery. 
- Drill does not require a centralized metadata repository.
- It features an in-memory shredded columnar representation for complex data which allows Drill to achieve columnar speed with the flexibility of an internal JSON document model.
- Drill supports a variety of NoSQL databases and file systems, including HBase, MongoDB, MapR-DB, HDFS, MapR-FS, Amazon S3, Azure Blob Storage, Google Cloud Storage, Swift, NAS and local files. 
- A single query can join data from multiple datastores. 
- For example, you can join a user profile collection in MongoDB with a directory of event logs in Hadoop.
- Drill's datastore-aware optimizer automatically restructures a query plan to leverage the datastore's internal processing capabilities.
- In addition, Drill supports data locality, so it's a good idea to co-locate Drill and the datastore on the same nodes.
- Drill leverages advanced query compilation and re-compilation techniques to maximize performance without requiring up-front schema knowledge.
- Drill supports standard SQL. Business users, analysts and data scientists can use standard BI/analytics tools such as Tableau, Qlik, MicroStrategy, Spotfire, SAS and Excel to interact with non-relational datastores by leveraging Drill's JDBC and ODBC drivers.
- Developers can leverage Drill's simple REST API in their custom applications to create beautiful visualizations.
- Drill's virtual datasets allow even the most complex, non-relational data to be mapped into BI-friendly structures which users can explore and visualize using their tool of choice.
- Drill's symmetrical architecture (all nodes are the same) and simple installation make it easy to deploy and operate very large clusters.
- Drill's design includes:
	- Columnar execution engine (the first ever to support complex data!)
	- Data-driven compilation and recompilation at execution time
	- Specialized memory management that reduces memory footprint and eliminates garbage collections
	- Locality-aware execution that reduces network traffic when Drill is co-located with the datastore
	- Advanced cost-based optimizer that pushes processing into the datastore when possible

******************************************Drill Architecture******************************************
- Drill includes a distributed execution environment, purpose built for large- scale data processing. 
- Drillbit: core of Apache Drill, which is responsible for accepting requests from the client, processing the queries, and returning results to the client.
- A Drillbit service can be installed and run on all of the required nodes in a Hadoop cluster to form a distributed cluster environment. When a Drillbit runs on each data node in the cluster, Drill can maximize data locality during query execution without moving data over the network or between nodes. 
- Drill uses ZooKeeper to maintain cluster membership and health-check information.
- Though Drill works in a Hadoop cluster environment, Drill is not tied to Hadoop and can run in any distributed cluster environment. 
- The only pre-requisite for Drill is ZooKeeper.
- Drill Clients:
	- you can access Drill from the following Clients: Drill-Shell, Drill Web-Console, ODBC and JDBC, C++ API.
- Drill Dynamic Schema discovery.
	- Drill does not require schema or type specification for data in order to start the query execution process. 
	- Drill starts data processing in record-batches and discovers the schema during processing.
	- Self-describing data formats such as Parquet, JSON, AVRO, and NoSQL databases have schema specified as part of the data itself, which Drill leverages dynamically at query time. 
	- Because the schema can change over the course of a Drill query, many Drill operators are designed to reconfigure themselves when schemas change.
- Flexible Data Model:
	- Drill allows access to nested data attributes, as if they were SQL columns, and provides intuitive extensions to easily operate on them. 
	- From an architectural point of view, Drill provides a flexible hierarchical columnar data model that can represent complex, highly dynamic and evolving data models. 
	- Relational data in Drill is treated as a special or simplified case of complex/multi-structured data.
- No centralized metadata:
	- Drill does not have a centralized metadata requirement.
	- You do not need to create and manage tables and views in a metadata repository, or rely on a database administrator group for such a function.
	- Drill metadata is derived through the storage plugins that correspond to data sources.
	- Storage plugins provide a spectrum of metadata ranging from full metadata (Hive), partial metadata (HBase), or no central metadata (files). 
	- De-centralized metadata means that Drill is NOT tied to a single Hive repository.
	- You can query multiple Hive repositories at once and then combine the data with information from HBase tables or with a file in a distributed file system.
	- You can also use SQL DDL statements to create metadata within Drill, which gets organized just like a traditional database.
	- Drill metadata is accessible through the ANSI standard INFORMATION_SCHEMA database.
- Extensibility:
	- Drill provides an extensible architecture at all layers, including the storage plugin, query, query optimization/execution, and client API layers.
	- You can customize any layer for the specific needs of an organization or you can extend the layer to a broader array of use cases. 
	- Drill uses classpath scanning to find and load plugins, and to add additional storage plugins, functions, and operators with minimal configuration.
	
******************************************Drill Query Execution******************************************
- When you submit a Drill query, the following were happening in Drill.
	- a client or an application sends the query in the form of an SQL statement to a Drillbit in the Drill cluster.
	- A Drillbit is the process running on each active Drill node that coordinates, plans, and executes queries, as well as distributes query work across the cluster to maximize data locality.
	- The following image represents the communication between clients, applications, and Drillbits (Reffer DrillQA.png)
- The Drillbit that receives the query from a client or application becomes the Foreman for the query and drives the entire query. 
- A parser in the Foreman parses the SQL, applying custom rules to convert specific SQL operators into a specific logical operator syntax that Drill understands.
- This collection of logical operators forms a logical plan. 
- The logical plan describes the work required to generate the query results and defines which data sources and operations to apply.
- The Foreman sends the logical plan into a cost-based optimizer to optimize the order of SQL operators in a statement and read the logical plan. 
- The optimizer applies various types of rules to rearrange operators and functions into an optimal plan. 
- The optimizer converts the logical plan into a physical plan that describes how to execute the query.
- Reffer (ForeMan_Process.png)
- A parallelizer in the Foreman transforms the physical plan into multiple phases, called major and minor fragments.
- These fragments create a multi-level execution tree that rewrites the query and executes it in parallel against the configured data sources, sending the results back to the client or application.
- Reffer (ForeMan_Fragments.png)
- Major Fragment:
	- A major fragment is a concept that represents a phase of the query execution. 
	- A phase can consist of one or multiple operations that Drill must perform to execute the query.
	- Drill assigns each major fragment a MajorFragmentID.
	- For Example:
		- to perform a hash aggregation of two files, Drill may create a plan with two major phases (major fragments) where the first phase is dedicated to scanning the two files and the second phase is dedicated to the aggregation of the data.
		- Reffer (ForeMan_MajorFragments.png)
		- Drill uses an exchange operator to separate major fragments. 
		- An exchange is a change in data location and/or parallelization of the physical plan.
		- An exchange is composed of a sender and a receiver to allow data to move between nodes.
		- Major fragments do not actually perform any query tasks. 
		- Each major fragment is divided into one or multiple minor fragments (discussed in the next section) that actually execute the operations required to complete the query and return results back to the client.
		- You can work with major fragments within the physical plan by capturing a JSON representation of the plan in a file, manually modifying it, and then submitting it back to Drill using the SUBMIT PLAN command. 
		- You can also view major fragments in the query profile, which is visible in the Drill Web Console. 	
- Minor Fragment:
	- Each major fragment is parallelized into minor fragments.
	- A minor fragment is a logical unit of work that runs inside a thread. 
	- A logical unit of work in Drill is also referred to as a slice.
	- The execution plan that Drill creates is composed of minor fragments. 
	- Drill assigns each minor fragment a MinorFragmentID.
	- Reffer (ForeMan_MinorFragments.png)
	- The parallelizer in the Foreman creates one or more minor fragments from a major fragment at execution time, by breaking a major fragment into as many minor fragments as it can usefully run at the same time on the cluster.
	- Drill executes each minor fragment in its own thread as quickly as possible based on its upstream data requirements.
	- Drill schedules the minor fragments on nodes with data locality. 
	- Otherwise, Drill schedules them in a round-robin fashion on the existing, available Drillbits.
	- Minor fragments contain one or more relational operators. 
	- An operator performs a relational operation, such as scan, filter, join, or group by. 
	- Each operator has a particular operator type and an OperatorID. 
	- Each OperatorID defines its relationship within the minor fragment to which it belongs. 
	- Reffer (physicalOperators.png)
	- You cannot modify the number of minor fragments within the execution plan.
	- However, you can view the query profile in the Drill Web Console and modify some configuration options that change the behavior of minor fragments, such as the maximum number of slices. 
- Execution of Minor Fragments
	- Minor fragments can run as root, intermediate, or leaf fragments. 
	- An execution tree contains only one root fragment.
	- The coordinates of the execution tree are numbered from the root, with the root being zero. 
	- Data flows downstream from the leaf fragments to the root fragment.
	- The root fragment runs in the Foreman and receives incoming queries, reads metadata from tables, rewrites the queries and routes them to the next level in the serving tree. 
	- The other fragments become intermediate or leaf fragments.
	- Intermediate fragments start work when data is available or fed to them from other fragments.
	- They perform operations on the data and then send the data downstream. 
	-  They also pass the aggregated results to the root fragment, which performs further aggregation and provides the query results to the client or application.
	- The leaf fragments scan tables in parallel and communicate with the storage layer or access data on local disk. 
	- The leaf fragments pass partial results to the intermediate fragments, which perform parallel operations on intermediate results.
	- Reffer (ForeMan_LeafFragment.png)
- Drill only plans queries that have concurrent running fragments. 
- For example, if 20 available slices exist in the cluster, Drill plans a query that runs no more than 20 minor fragments in a particular major fragment

************************************************Core Modules*********************************************
- Reffer Drillbit Components(Core Module)
- RPC Endpoint: 
	- Drill exposes a low overhead protobuf-based RPC protocol to communicate with the clients. 
	- Additionally, C++ and Java API layers are also available for client applications to interact with Drill.
	- Clients can communicate with a specific Drillbit directly or go through a ZooKeeper quorum to discover the available Drillbits before submitting queries.
	- It is recommended that the clients always go through ZooKeeper to shield clients from the intricacies of cluster management, such as the addition or removal of nodes.
- SQL Parser:
	- Drill uses Calcite, the open source SQL parser framework, to parse incoming queries. 
	- The output of the parser component is a language agnostic, computer-friendly logical plan that represents the query.
	- Notes: Calcite -> https://calcite.incubator.apache.org/
- Storage Plugin Interface:
	- Drill serves as a query layer on top of several data sources.
	- Storage plugins in Drill represent the abstractions that Drill uses to interact with the data sources. 
	- Storage plugins provide Drill with the following information:
		- Metadata available in the source
		- Interfaces for Drill to read from and write to data sources
		- Location of data and a set of optimization rules to help with efficient and fast execution of Drill queries on a specific data source
	- Drill provides storage plugins for distributed files and HBase. Drill also integrates with Hive using a storage plugin.
	- Drill integration with Hive is only for metadata. Drill does not invoke the Hive execution engine for any requests.

	
*********************Performance**************************
- Distributed engine
- Columnar execution
- Vectorization
- Runtime compilation
- Optimistic and pipelined query execution


	
	
	
	
Reference:	
- Download Link: https://drill.apache.org/download/
- Documentation Link: https://drill.apache.org/docs/