******************Apachi Nifi*************************
- NiFi was built to automate the flow of data between systems. 
- While the term dataflow is used in a variety of contexts, we use it here to mean the automated and managed flow of information between systems. 
- A comprehensive and readily consumed form is found in the Enterprise Integration Patterns [eip].


Some of the high-level challenges of dataflow include:
1) Systems fail
	- Networks fail
	- Disks fail
	- Software crashes
	- People make mistakes.
2) Data access exceeds capacity to consume
	- Sometimes a given data source can outpace some part of the processing or delivery chain - it only takes one weak-link to have an issue.
3) Boundary conditions are mere suggestions
	- You will invariably get data that is too big, too small, too fast, too slow, corrupt, wrong, or in the wrong format.
4) What is noise one day becomes signal the next
	- Priorities of an organization change - rapidly.
	- Enabling new flows and changing existing ones must be fast.
5) Systems evolve at different rates
	- The protocols and formats used by a given system can change anytime and often irrespective of the systems around them. 
6) Compliance and security
	- Laws, regulations, and policies change.
	- Business to business agreements change. 
	- in this case System to system and system to user interactions must be secure, trusted, accountable.
7) Continuous improvement occurs in production


******************Core Concept of NiFi****************************
NiFi’s fundamental design concepts closely relate to the main ideas of Flow Based Programming [FBP]
1) FlowFile (Information Packet)
	- A FlowFile represents each object moving through the system and for each one, 
	  NiFi keeps track of a map of key/value pair attribute strings and its associated content of zero or more bytes.

2) FlowFile Processor (Black Box)
	- Processors actually perform the work.
	- In [eip] terms a processor is doing some combination of data routing, transformation, or mediation between systems.
	- Processors have access to attributes of a given FlowFile and its content stream.
	- Processors can operate on zero or more FlowFiles in a given unit of work and either commit that work or rollback.

3) Connection (Bounded Buffer)
	- Connections provide the actual linkage between processors. 
	- These act as queues and allow various processes to interact at differing rates. 
	- These queues can be prioritized dynamically and can have upper bounds on load, which enable back pressure.

4) Flow Controller (Scheduler)
	- The Flow Controller maintains the knowledge of how processes connect and manages the threads and allocations thereof which all processes use.
	- The Flow Controller acts as the broker facilitating the exchange of FlowFiles between processors.

5) Process Group (subnet)
	- A Process Group is a specific set of processes and their connections, 
	- which can receive data via input ports and send data out via output ports.
	- In this manner, process groups allow creation of entirely new components simply by composition of other components.

***************NiFi Architecture*************************************
	- OS/Host
		- JVM
			- Web Server
			- Flow Controller
				- Processor 1
				- Extension N
			- Flow File Repoisitory
			- Content Repository
			- Provenance Repository
		- Local Storage

The primary components of NiFi on the JVM are as follows:
1) Web server
	- The purpose of the web server is to host NiFi’s HTTP-based command and control API.
2) Flow Controller (Scheduler)
	- The flow controller is the brains of the operation.
	- It provides threads for extensions to run on, and manages the schedule of when extensions receive resources to execute.
3) Extensions
	- The key point here is that extensions operate and execute within the JVM.
4) FlowFile Repository
	- The FlowFile Repository is where NiFi keeps track of the state of what it knows about a given FlowFile that is presently active in the flow.
	- The implementation of the repository is pluggable. 
	- The default approach is a persistent Write-Ahead Log located on a specified disk partition.
5) Content Repository
	- The Content Repository is where the actual content bytes of a given FlowFile live.
	- The implementation of the repository is pluggable.
	- The default approach is a fairly simple mechanism, which stores blocks of data in the file system.
	- More than one file system storage location can be specified so as to get different physical partitions engaged to reduce contention on any single volume.
6) Provenance Repository
	- The Provenance Repository is where all provenance event data is stored.
	- The repository construct is pluggable with the default implementation being to use one or more physical disk volumes. 
	- Within each location event data is indexed and searchable.


*************NiFi Within Cluster**************
- NiFi is also able to operate within a cluster
- Starting with the NiFi 1.0 release, a Zero-Master Clustering paradigm is employed.
- Each node in a NiFi cluster performs the same tasks on the data, but each operates on a different set of data. 
- Apache ZooKeeper elects a single node as the Cluster Coordinator, and failover is handled automatically by ZooKeeper. 
- All cluster nodes report heartbeat and status information to the Cluster Coordinator. 
- The Cluster Coordinator is responsible for disconnecting and connecting nodes. 
- Additionally, every cluster has one Primary Node, also elected by ZooKeeper. 
- As a DataFlow manager, you can interact with the NiFi cluster through the user interface (UI) of any node. 
- Any change you make is replicated to all nodes in the cluster, allowing for multiple entry points.


************Key Features of NiFi*************
1) Flow Management
	- Guaranteed Delivery
		- A core philosophy of NiFi has been that even at very high scale, guaranteed delivery is a must. 
		- This is achieved through effective use of a purpose-built persistent write-ahead log and content repository.
		- Together they are designed in such a way as to allow for very high transaction rates, 
		  effective load-spreading, copy-on-write, and play to the strengths of traditional disk read/writes. 
	- Data Buffering w/ Back Pressure and Pressure Release
		- NiFi supports buffering of all queued data as well as the ability to provide back pressure as those queues reach specified limits or to age off data
		  as it reaches a specified age (its value has perished).
	- Prioritized Queuing
		- NiFi allows the setting of one or more prioritization schemes for how data is retrieved from a queue.
		- The default is oldest first, but there are times when data should be pulled newest first, largest first, or some other custom scheme.
	- Flow Specific QoS (latency v throughput, loss tolerance, etc.)
		- There are points of a dataflow where the data is absolutely critical and it is loss intolerant. 
		- There are also times when it must be processed and delivered within seconds to be of any value. 
		- NiFi enables the fine-grained flow specific configuration of these concerns.
2) Ease of Use
	- Visual Command and Control
		- Dataflows can become quite complex. 
		- Being able to visualize those flows and express them visually can help greatly to reduce that complexity and to identify areas that need to be simplified.
		- NiFi enables not only the visual establishment of dataflows but it does so in real-time. 
		- Rather than being design and deploy it is much more like molding clay.
		- If you make a change to the dataflow that change immediately takes effect. 
		- Changes are fine-grained and isolated to the affected components. 
		- You don’t need to stop an entire flow or set of flows just to make some specific modification.
	- Flow Templates
		- Dataflows tend to be highly pattern oriented and while there are often many different ways to solve a problem, it helps greatly to be able to share those best practices.
	- Data Provenance
		- NiFi automatically records, indexes, and makes available provenance data as objects flow through the system even across fan-in, fan-out, transformations, and more.
		- This information becomes extremely critical in supporting compliance, troubleshooting, optimization, and other scenarios.
	- Recovery / Recording a rolling buffer of fine-grained history
		- NiFi’s content repository is designed to act as a rolling buffer of history. 
		- Data is removed only as it ages off the content repository or as space is needed.
3) Security
	- System to System
		- A dataflow is only as good as it is secure.
		- NiFi at every point in a dataflow offers secure exchange through the use of protocols with encryption such as 2-way SSL.
		- In addition NiFi enables the flow to encrypt and decrypt content and use shared-keys or other mechanisms on either side of the sender/recipient equation.
	- User to System
		- NiFi enables 2-Way SSL authentication and provides pluggable authorization so that it can properly control a user’s access and at particular levels.
		- If a user enters a sensitive property like a password into the flow, it is immediately encrypted server side and never again exposed on the client side even in its encrypted form.
	- Multi-tenant Authorization
		- The authority level of a given dataflow applies to each component, allowing the admin user to have fine grained level of access control. 
		- This means each NiFi cluster is capable of handling the requirements of one or more organizations. 
		- Compared to isolated topologies, multi-tenant authorization enables a self-service model for dataflow management, 
		  allowing each team or organization to manage flows with a full awareness of the rest of the flow, to which they do not have access.
4) Extensible Architecture
	- Extension
		- NiFi is at its core built for extension and as such it is a platform on which dataflow processes can execute and interact in a predictable and repeatable manner. 
		- Points of extension include: processors, Controller Services, Reporting Tasks, Prioritizers, and Customer User Interfaces.
	- Classloader Isolation
		- For any component-based system, dependency problems can quickly occur.
		- NiFi addresses this by providing a custom class loader model, ensuring that each extension bundle is exposed to a very limited set of dependencies.
		- As a result, extensions can be built with little concern for whether they might conflict with another extension.
	- Site-to-Site Communication Protocol
		- The preferred communication protocol between NiFi instances is the NiFi Site-to-Site (S2S) Protocol. 
		- S2S makes it easy to transfer data from one NiFi instance to another easily, efficiently, and securely. 
		- NiFi client libraries can be easily built and bundled into other applications or devices to communicate back to NiFi via S2S.
		- Both the socket based protocol and HTTP(S) protocol are supported in S2S as the underlying transport protocol, making it possible to embed a proxy server into the S2S communication.
5) Flexible Scaling Model
	- Scale-out (Clustering)
		- NiFi is designed to scale-out through the use of clustering many nodes together as described above.
		- If a single node is provisioned and configured to handle hundreds of MB per second, then a modest cluster could be configured to handle GB per second.
		- This then brings about interesting challenges of load balancing and fail-over between NiFi and the systems from which it gets data.
		- Use of asynchronous queuing based protocols like messaging services, Kafka, etc., can help.
		- Use of NiFi’s site-to-site feature is also very effective as it is a protocol that allows NiFi and a client (including another NiFi cluster) to talk to each other, share information about loading, and to exchange data on specific authorized ports.
	- Scale-up & down
		- NiFi is also designed to scale-up and down in a very flexible manner. 
		- In terms of increasing throughput from the standpoint of the NiFi framework, it is possible to increase the number of concurrent tasks on the processor under the Scheduling tab when configuring. 
		- This allows more processes to execute simultaneously, providing greater throughput.

****************Configuration****************************
1) pre requisites
	- Java 8
	- Linux
	- Web Browser
2) Configuration
	- Untar the File
	- do the needed configurations in nifi.properties file
	- run NiFi using the following command from inside the Bin folder.
		./nifi.sh start - to Start the service background
		./nifi.sh stop - to stop the service background
		./nifi.sh status - to check the status of the nifi service
		./nifi.sh run - to start the nifi service foreground and wait for CTRL+C to stor the Nifi
***********************************************************
*****************Creating custom Nifi package**************
Steps to create new Nifi maven project
1) mvn archetype:generate
2)type "nifi" and search for nifi realted bundles
3) from the output search for " org.apache.nifi:nifi-processor-bundle-archetype" and enter the respective number
4) choose respective number for the version you are expecting
5) type the required Details


Ref:
	https://community.hortonworks.com/articles/4318/build-custom-nifi-processor.htmlRef:
**********************************************************